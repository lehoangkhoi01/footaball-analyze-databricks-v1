{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f159ace4-3b3f-40e7-abdd-61fb6ae17fd7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.api.api_handler import APIError, APIRequestHandler\n",
    "from src.api.endpoints import FIXTURE_STATS_ENDPOINT\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "rootUrl = dbutils.secrets.get(scope=\"football-analyze\", key=\"api-url\")\n",
    "api_key = dbutils.secrets.get(scope=\"football-analyze\", key=\"api-key\")\n",
    "api_host = \"v3.football.api-sports.io\"\n",
    "\n",
    "# Define headers\n",
    "headers = {\n",
    "    'x-rapidapi-host': api_host,\n",
    "    'x-rapidapi-key': api_key\n",
    "}\n",
    "\n",
    "REQUESTS_PER_MINUTE = 10\n",
    "DELAY = 60 / REQUESTS_PER_MINUTE  # 6 seconds between requests\n",
    "\n",
    "def fetch_fixture_stats(fixture_id: int):\n",
    "    with APIRequestHandler(base_url=rootUrl) as api:\n",
    "        try:\n",
    "            response = api.fetch_with_rate_limit(DELAY, headers, FIXTURE_STATS_ENDPOINT, params={'fixture': fixture_id})\n",
    "            resultCount = response.__getitem__('results')\n",
    "            errors = response.__getitem__('errors')\n",
    "            if errors:\n",
    "                raise ValueError(f\"Errors - fetch_fixture_stats: {errors}\")\n",
    "            if not resultCount:\n",
    "                print('Empty data from fetching Fixture Stats endpoint')\n",
    "                raise ValueError(f\"No stats found for fixture ID: {fixture_id}\")\n",
    "            else:\n",
    "                fixtures_stats_data = response.get('response', [])\n",
    "                return {\n",
    "                            'fixture_id': fixture_id,\n",
    "                            'stats': fixtures_stats_data,\n",
    "                            'fetched_at': datetime.now().isoformat()\n",
    "                        }\n",
    "        except APIError as e:\n",
    "            raise ValueError(\"Error from fetch_fixture_stats: \", e)\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Error from fetch_fixture_stats: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "64a36ef1-5f33-46bc-a53e-34697c65ad69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "from itertools import chain\n",
    "\n",
    "def process_combination_fetch_fixtures_stats(fixture_ids, league_id):\n",
    "    results = []\n",
    "\n",
    "    # Process with controlled parallelism\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        # Map fixture_ids to fetch_fixture_stats function\n",
    "        future_to_fixture = {\n",
    "            executor.submit(fetch_fixture_stats, fixture_id): fixture_id\n",
    "            for fixture_id in fixture_ids\n",
    "        }\n",
    "\n",
    "        # Collect results as they complete\n",
    "        for future in concurrent.futures.as_completed(future_to_fixture):\n",
    "            fixture_id = future_to_fixture[future]\n",
    "            try:\n",
    "                result= future.result()\n",
    "                result[\"league_id\"] = league_id\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                raise Exception(f\"Processing failed for fixture ID {fixture_id}: {str(e)}\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3c6d95a-9ece-4c9b-bda2-b90c2131f7bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from src.schemas.stats_tracking_schema import StatsTrackingSchema\n",
    "from src.utils.fixture_stats_tracking_util import FixtureStatsHandler\n",
    "import json\n",
    "from pyspark.sql.functions import *\n",
    "from datetime import datetime\n",
    "\n",
    "LIMIT_TO_FETCH = 3\n",
    "\n",
    "league_progress_tracking_df = (spark.read\n",
    "    .format(\"json\")\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .schema(StatsTrackingSchema.get_league_stat_tracking_schema())\n",
    "    .load(f\"/Volumes/football-analyze-v1/football/api-raw-data/tracking/fixture_stat_league\")\n",
    ")\n",
    "\n",
    "fixture_tracking_df = (spark.read\n",
    "    .format(\"json\")\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .schema(StatsTrackingSchema.get_fixture_stat_tracking_schema())\n",
    "    .load(f\"/Volumes/football-analyze-v1/football/api-raw-data/tracking/fixture_stats\")\n",
    ")\n",
    "handler = FixtureStatsHandler(\n",
    "    fixture_stats_tracking_df = fixture_tracking_df,\n",
    "    league_progress_tracking_df = league_progress_tracking_df,\n",
    "    spark = spark\n",
    ")\n",
    "\n",
    "fixtures_to_fetch  = handler.get_next_fixtures_to_fetch(limit=LIMIT_TO_FETCH)\n",
    "fixture_ids_list = [fixtures['fixture_id'] for fixtures in fixtures_to_fetch]\n",
    "if (len(fixtures_to_fetch) <= 0):\n",
    "    raise Exception(\"Can not find next fixture to fetch\")\n",
    "league_id = fixtures_to_fetch[0]['league_id']\n",
    "\n",
    "# --------------------------------------------------------\n",
    "\n",
    "all_data = process_combination_fetch_fixtures_stats(fixture_ids_list, league_id)\n",
    "if not all_data:\n",
    "    raise Exception('Error - Empty data from fetching Fixture Stats endpoint')\n",
    "else:\n",
    "    # Update tracking progress of fetching Fixture stats\n",
    "    fetched_fixture_id_list = [fixture['fixture_id'] for fixture in all_data]\n",
    "    if fetched_fixture_id_list is None or len(fetched_fixture_id_list) <= 0:\n",
    "        raise ValueError(\"Fetched fixture IDs list is empty.\")\n",
    "    # Update table tracking\n",
    "    handler.mark_fixtures_fetched(fetched_fixture_id_list, league_id)\n",
    "    latest_stat_tracking_df = handler.get_fixture_stats()\n",
    "    latest_league_progress_df = handler.get_league_progress_tracking()\n",
    "\n",
    "    # ---------- Save fixture stats tracking\n",
    "    for row in latest_stat_tracking_df.select(\"league_id\").distinct().collect():\n",
    "        league_id = row[\"league_id\"]\n",
    "        group_df = latest_stat_tracking_df.filter(\n",
    "            (col(\"league_id\") == league_id)\n",
    "        )\n",
    "        dict_list = [row.asDict() for row in group_df.collect()]\n",
    "        json_data = json.dumps(dict_list, indent=2, sort_keys=True, default=str)\n",
    "        output_path = f\"/Volumes/football-analyze-v1/football/api-raw-data/tracking/fixture_stats/league_{league_id}.json\"\n",
    "        dbutils.fs.put(output_path, json_data, True)\n",
    "\n",
    "    # ---------- Save league progress tracking\n",
    "    league_progress_list = [row.asDict() for row in latest_league_progress_df.collect()]\n",
    "    json_league_progress = json.dumps(league_progress_list, indent=2, sort_keys=True, default=str)\n",
    "    league_tracking_file_name = f\"/Volumes/football-analyze-v1/football/api-raw-data/tracking/fixture_stat_league/league_progress.json\"\n",
    "    dbutils.fs.put(league_tracking_file_name, json_league_progress, True)\n",
    "\n",
    "    # Save as JSON into Volume\n",
    "    json_data = json.dumps(all_data, indent=2, sort_keys=True, default=str)\n",
    "    batch_file_name = f\"/Volumes/football-analyze-v1/football/api-raw-data/fixture_stats/stats_{league_id}_{datetime.now()}.json\"\n",
    "    batch_row_count = len(all_data)\n",
    "    batch_ingestion_time = str(datetime.now())\n",
    "    dbutils.fs.put(batch_file_name, json_data, True)\n",
    "    print(\"Complete writing files\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Daily - Fetch Fixture Stats",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
